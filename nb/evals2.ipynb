{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/zsucicdl/lentil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"/content/drive/My Drive/data/skill_builder_data.csv\"\n",
    "df = pd.read_csv(path,\n",
    "                 dtype={'order_id': int, 'assignment_id': int, 'user_id': int, 'assistment_id': int, 'problem_id': int,\n",
    "                        'original': int, 'correct': int, 'attempt_count': int, 'ms_first_response': int,\n",
    "                        'tutor_mode': 'string', 'answer_type': 'string', 'sequence_id': int, 'student_class_id': int,\n",
    "                        'position': int, 'type': 'string', 'base_sequence_id': int, 'skill_id': float,\n",
    "                        'skill_name': 'string',\n",
    "                        'teacher_id': int, 'school_id': int, 'hint_count': int, 'hint_total': int, 'overlap_time': int,\n",
    "                        'template_id': int, 'answer_id': int, 'answer_text': 'string', 'first_action': int,\n",
    "                        'bottom_hint': int, 'opportunity': int, 'opportunity_original': int\n",
    "                        },\n",
    "                 usecols=['order_id', 'assignment_id', 'user_id', 'assistment_id', 'problem_id', 'original', 'correct',\n",
    "                          'attempt_count', 'ms_first_response', 'tutor_mode', 'answer_type', 'sequence_id',\n",
    "                          'student_class_id', 'position', 'type', 'base_sequence_id', 'skill_id', 'skill_name',\n",
    "                          'teacher_id', 'school_id', 'hint_count', 'hint_total', 'overlap_time', 'template_id',\n",
    "                          'first_action', 'opportunity', ])\n",
    "print(\"Input done.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "from lentil import evaluate\n",
    "from lentil.util import *\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "history_path = '/home/zvonimir/PycharmProjects/lentil/data/skill_builder_data.csv'\n",
    "df = pd.read_csv(history_path,\n",
    "                 dtype={'order_id': int, 'assignment_id': int, 'user_id': int, 'assistment_id': int, 'problem_id': int,\n",
    "                        'original': int, 'correct': int, 'attempt_count': int, 'ms_first_response': int,\n",
    "                        'tutor_mode': 'string', 'answer_type': 'string', 'sequence_id': int, 'student_class_id': int,\n",
    "                        'position': int, 'type': 'string', 'base_sequence_id': int, 'skill_id': float,\n",
    "                        'skill_name': 'string',\n",
    "                        'teacher_id': int, 'school_id': int, 'hint_count': int, 'hint_total': int, 'overlap_time': int,\n",
    "                        'template_id': int, 'answer_id': int, 'answer_text': 'string', 'first_action': int,\n",
    "                        'bottom_hint': int, 'opportunity': int, 'opportunity_original': int\n",
    "                        },\n",
    "                 usecols=['order_id', 'assignment_id', 'user_id', 'assistment_id', 'problem_id', 'original', 'correct',\n",
    "                          'attempt_count', 'ms_first_response', 'tutor_mode', 'answer_type', 'sequence_id',\n",
    "                          'student_class_id', 'position', 'type', 'base_sequence_id', 'skill_id', 'skill_name',\n",
    "                          'teacher_id', 'school_id', 'hint_count', 'hint_total', 'overlap_time', 'template_id',\n",
    "                          'first_action', 'opportunity', ])\n",
    "\n",
    "unfiltered_history = interaction_history_from_assistments_data_set(\n",
    "    df,\n",
    "    module_id_column='problem_id',\n",
    "    duration_column='ms_first_response')\n",
    "\n",
    "REPEATED_FILTER = 3  # number of times to repeat filtering\n",
    "history = reduce(\n",
    "    lambda acc, _: filter_history(acc, min_num_ixns=75, max_num_ixns=1000),\n",
    "    range(REPEATED_FILTER), unfiltered_history)\n",
    "\n",
    "# history = datatools.InteractionHistory(filtered_history)\n",
    "df = history.data\n",
    "\n",
    "model_builders = {}\n",
    "\n",
    "# baselines\n",
    "model_builders = {\n",
    "    '0PL IRT (students)': build_student_biased_coin_model,\n",
    "    '0PL IRT (assessments)': build_assessment_biased_coin_model,\n",
    "    '1PL IRT': build_1pl_irt_model,\n",
    "    '2PL IRT': build_2pl_irt_model  # ,\n",
    "    # '2D MIRT' : meta_build_mirt_model(dims=2)\n",
    "}\n",
    "\n",
    "learning_update_variances = [1e-8, 1e-6, 1e-4, 1e-2, 0.5, 10., 100., 1000.]\n",
    "\n",
    "# vary learning_update_variance\n",
    "for var in learning_update_variances:\n",
    "    model_builders['d=2, with bias, var=%f' % var] = meta_build_embedding(\n",
    "        d=2,\n",
    "        using_lessons=True,\n",
    "        using_prereqs=True,\n",
    "        using_bias=True,\n",
    "        learning_update_variance_constant=var)\n",
    "\n",
    "# high learning_update_variance should simulate having no lessons\n",
    "model_builders['d=2, without lessons, with bias'] = meta_build_embedding(\n",
    "    d=2,\n",
    "    using_lessons=False,\n",
    "    using_prereqs=False,\n",
    "    using_bias=True)\n",
    "\n",
    "regularization_constants = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 0.1, 1., 10.]\n",
    "\n",
    "# vary regularization_constant\n",
    "for const in regularization_constants:\n",
    "    model_builders['d=2, with bias, regularization_constant=%f' % const] = meta_build_embedding(\n",
    "        d=2,\n",
    "        using_lessons=True,\n",
    "        using_prereqs=True,\n",
    "        using_bias=True,\n",
    "        regularization_constant=const)\n",
    "\n",
    "    # the effect of varying regularization\n",
    "    # is probably stronger when there are no bias terms\n",
    "    model_builders['d=2, without bias, regularization_constant=%f' % const] = meta_build_embedding(\n",
    "        d=2,\n",
    "        using_lessons=True,\n",
    "        using_prereqs=True,\n",
    "        using_bias=False,\n",
    "        regularization_constant=const)\n",
    "\n",
    "# grid of regularization_constant and embedding_dimension values\n",
    "embedding_dimensions = [2, 5, 10, 20, 50]\n",
    "regularization_constants = [1e-8, 1e-6, 1e-4, 1e-2, 1.]\n",
    "\n",
    "for d in embedding_dimensions:\n",
    "    for const in regularization_constants:\n",
    "        model_builders['d=%d, with bias, regularization_constant=%f' % (d, const)] = meta_build_embedding(\n",
    "            d=d,\n",
    "            using_lessons=True,\n",
    "            using_prereqs=True,\n",
    "            using_bias=True,\n",
    "            regularization_constant=const,\n",
    "            using_scipy=(d <= 10))\n",
    "\n",
    "        # the effect of varying dimension and regularization\n",
    "        # is probably stronger when there are no bias terms\n",
    "        model_builders['d=%d, without bias, regularization_constant=%f' % (d, const)] = meta_build_embedding(\n",
    "            d=d,\n",
    "            using_lessons=True,\n",
    "            using_prereqs=True,\n",
    "            using_bias=False,\n",
    "            regularization_constant=const,\n",
    "            using_scipy=(d <= 10))\n",
    "\n",
    "# lesion analysis\n",
    "\n",
    "# baselines\n",
    "model_builders = {\n",
    "    '0PL IRT (assessments)': build_student_biased_coin_model,\n",
    "    '0PL IRT (students)': build_assessment_biased_coin_model,\n",
    "    '1PL IRT': build_1pl_irt_model,\n",
    "    '2PL IRT': build_2pl_irt_model,\n",
    "    '2D MIRT': meta_build_mirt_model(dims=2)\n",
    "}\n",
    "\n",
    "# lesson|prereq|bias\n",
    "# Y|Y|Y\n",
    "model_builders['d=2, with prereqs and bias'] = meta_build_embedding(\n",
    "    d=2,\n",
    "    using_lessons=True,\n",
    "    using_prereqs=True,\n",
    "    using_bias=True)\n",
    "\n",
    "# Y|Y|N\n",
    "model_builders['d=2, with prereqs, without bias'] = meta_build_embedding(\n",
    "    d=2,\n",
    "    using_prereqs=True,\n",
    "    using_lessons=True,\n",
    "    using_bias=False)\n",
    "\n",
    "# Y|N|N\n",
    "model_builders['d=2, without prereqs and bias'] = meta_build_embedding(\n",
    "    d=2,\n",
    "    using_prereqs=False,\n",
    "    using_lessons=True,\n",
    "    using_bias=False)\n",
    "\n",
    "# Y|N|Y\n",
    "model_builders['d=2, without prereqs, with bias'] = meta_build_embedding(\n",
    "    d=2,\n",
    "    using_prereqs=False,\n",
    "    using_lessons=True,\n",
    "    using_bias=True)\n",
    "\n",
    "# N|N|N\n",
    "model_builders['d=2, without lessons and bias'] = meta_build_embedding(\n",
    "    d=2,\n",
    "    using_lessons=False,\n",
    "    using_prereqs=False,\n",
    "    using_bias=False)\n",
    "\n",
    "# N|N|Y\n",
    "model_builders['d=2, without lessons, with bias'] = meta_build_embedding(\n",
    "    d=2,\n",
    "    using_lessons=False,\n",
    "    using_prereqs=False,\n",
    "    using_bias=True)\n",
    "\n",
    "# check how varying dimension and regularization affects MIRT\n",
    "regularization_constants = [1e-2, 0.1, 1., 10.]\n",
    "dimensions = [1, 2, 5, 10, 20]\n",
    "\n",
    "# baselines\n",
    "model_builders = {\n",
    "    '0PL IRT (assessments)': build_student_biased_coin_model,\n",
    "    '0PL IRT (students)': build_assessment_biased_coin_model,\n",
    "    '1PL IRT': build_1pl_irt_model,\n",
    "    '2PL IRT': build_2pl_irt_model\n",
    "}\n",
    "\n",
    "for d in dimensions:\n",
    "    for r in regularization_constants:\n",
    "        model_builders['%dD MIRT, with regularization_constant=%f' % (\n",
    "            d, r)] = meta_build_mirt_model(regularization_constant=r, dims=d)\n",
    "\n",
    "print \"Number of models = %d\" % (len(model_builders))\n",
    "print '\\n'.join(model_builders.keys())\n",
    "\n",
    "results = evaluate.cross_validated_auc(\n",
    "    model_builders,\n",
    "    history,\n",
    "    num_folds=10,\n",
    "    random_truncations=False)\n",
    "\n",
    "results_path = os.path.join(\n",
    "    'results', 'last', 'lse_synthetic_results.pkl')\n",
    "\n",
    "# dump results to file\n",
    "with open(results_path, 'wb') as f:\n",
    "    pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# load results from file, replacing current results\n",
    "with open(results_path, 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "# load results from file, merging with current results\n",
    "with open(results_path, 'rb') as f:\n",
    "    results = results.merge(pickle.load(f))\n",
    "\n",
    "# compare models to baselines\n",
    "baselines = ['0PL IRT (students)', '0PL IRT (assessments)', '1PL IRT', '2PL IRT']\n",
    "for baseline in baselines:\n",
    "    for k in results.raw_results:\n",
    "        if k == baseline:\n",
    "            continue\n",
    "        print \"%s vs. %s:\" % (k, baseline)\n",
    "        print \"p-value = %f\" % (results.compare_validation_aucs(k, baseline))\n",
    "        print ''\n",
    "\n",
    "# compare with lessons to without lessons\n",
    "print \"without bias:\"\n",
    "print \"p-value = %f\" % (results.compare_validation_aucs(\n",
    "    'd=2, without lessons and bias',\n",
    "    'd=2, without prereqs and bias'))\n",
    "print ''\n",
    "print \"with bias:\"\n",
    "print \"p-value = %f\" % (results.compare_validation_aucs(\n",
    "    'd=2, without lessons, with bias',\n",
    "    'd=2, without prereqs, with bias'))\n",
    "\n",
    "# compare with prereqs to without prereqs\n",
    "print \"without bias:\"\n",
    "print \"p-value = %f\" % (results.compare_validation_aucs(\n",
    "    'd=2, with prereqs, without bias',\n",
    "    'd=2, without prereqs and bias'))\n",
    "print ''\n",
    "print \"with bias:\"\n",
    "print \"p-value = %f\" % (results.compare_validation_aucs(\n",
    "    'd=2, with prereqs and bias',\n",
    "    'd=2, without prereqs, with bias'))\n",
    "\n",
    "# compare with bias to without bias\n",
    "print \"with prereqs:\"\n",
    "print \"p-value = %f\" % (results.compare_validation_aucs(\n",
    "    'd=2, with prereqs, without bias',\n",
    "    'd=2, with prereqs and bias'))\n",
    "print ''\n",
    "print \"without prereqs:\"\n",
    "print \"p-value = %f\" % (results.compare_validation_aucs(\n",
    "    'd=2, without prereqs and bias',\n",
    "    'd=2, without prereqs, with bias'))\n",
    "print ''\n",
    "print \"without lessons:\"\n",
    "print \"p-value = %f\" % (results.compare_validation_aucs(\n",
    "    'd=2, without lessons and bias',\n",
    "    'd=2, without lessons, with bias'))\n",
    "\n",
    "print 'Train\\tValidation\\tTest\\tModel'\n",
    "names = ['0PL IRT (students)', '0PL IRT (assessments)', '1PL IRT', '2PL IRT', 'd=2, without lessons and bias',\n",
    "         'd=2, without lessons, with bias', 'd=2, without prereqs and bias', 'd=2, without prereqs, with bias',\n",
    "         'd=2, with prereqs, without bias', 'd=2, with prereqs and bias']\n",
    "for k in names:\n",
    "    try:\n",
    "        train_auc = results.training_auc_mean(k)\n",
    "        val_auc = results.validation_auc_mean(k)\n",
    "        test_auc = results.test_auc(k)\n",
    "    except KeyError:\n",
    "        continue\n",
    "    print '%0.3f\\t%0.3f\\t\\t%0.3f\\t%s' % (train_auc, val_auc, test_auc, k)\n",
    "\n",
    "\n",
    "def plot_d_vs_beta_grid(using_bias=True):\n",
    "    with_or_without_bias = 'with' if using_bias else 'without'\n",
    "    _, ax = plt.subplots()\n",
    "\n",
    "    plt.xlabel('Embedding dimension')\n",
    "    plt.ylabel('Area under ROC Curve')\n",
    "    plt.title('Validation Performance')\n",
    "\n",
    "    for const in regularization_constants:\n",
    "        ax.plot(\n",
    "            embedding_dimensions,\n",
    "            [results.validation_auc_mean('d=%d, %s bias, regularization_constant=%f' % (\n",
    "                d, with_or_without_bias, const)) for d in embedding_dimensions],\n",
    "            '-s', label='beta=%f, %s bias' % (const, with_or_without_bias))\n",
    "\n",
    "    ax.plot(embedding_dimensions, [results.validation_auc_mean('0PL IRT (students)')] * len(embedding_dimensions),\n",
    "            '--', label='0PL IRT (students)')\n",
    "    ax.plot(embedding_dimensions, [results.validation_auc_mean('0PL IRT (assessments)')] * len(embedding_dimensions),\n",
    "            '--', label='0PL IRT (assessments)')\n",
    "    ax.plot(embedding_dimensions, [results.validation_auc_mean('1PL IRT')] * len(embedding_dimensions),\n",
    "            '--', label='1PL IRT')\n",
    "    ax.plot(embedding_dimensions, [results.validation_auc_mean('2PL IRT')] * len(embedding_dimensions),\n",
    "            '--', label='2PL IRT')\n",
    "\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.legend(bbox_to_anchor=(1., 1.))\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xticks(embedding_dimensions)\n",
    "    ax.set_xticklabels([str(x) for x in embedding_dimensions])\n",
    "    ax.get_xaxis().get_major_formatter().labelOnlyBase = False\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_d_vs_beta_grid(using_bias=True)\n",
    "\n",
    "plot_d_vs_beta_grid(using_bias=False)\n",
    "\n",
    "plt.xlabel('Regularization constant')\n",
    "plt.ylabel('Area under ROC Curve')\n",
    "plt.title('Validation Performance')\n",
    "\n",
    "plt.errorbar(\n",
    "    regularization_constants,\n",
    "    [results.validation_auc_mean('d=2, with bias, regularization_constant=%f' % const) for const in\n",
    "     regularization_constants],\n",
    "    yerr=[1.96 * results.validation_auc_stderr('d=2, with bias, regularization_constant=%f' % const) for const in\n",
    "          regularization_constants],\n",
    "    label='d=2, with bias')\n",
    "\n",
    "plt.errorbar(\n",
    "    regularization_constants,\n",
    "    [results.validation_auc_mean('d=2, without bias, regularization_constant=%f' % const) for const in\n",
    "     regularization_constants],\n",
    "    [1.96 * results.validation_auc_stderr('d=2, without bias, regularization_constant=%f' % const) for const in\n",
    "     regularization_constants],\n",
    "    label='d=2, without bias')\n",
    "\n",
    "plt.plot(regularization_constants, [results.validation_auc_mean('0PL IRT (students)')] * len(regularization_constants),\n",
    "         '--', label='0PL IRT (students)')\n",
    "plt.plot(regularization_constants,\n",
    "         [results.validation_auc_mean('0PL IRT (assessments)')] * len(regularization_constants),\n",
    "         '--', label='0PL IRT (assessments)')\n",
    "plt.plot(regularization_constants, [results.validation_auc_mean('1PL IRT')] * len(regularization_constants),\n",
    "         '--', label='1PL IRT')\n",
    "plt.plot(regularization_constants, [results.validation_auc_mean('2PL IRT')] * len(regularization_constants),\n",
    "         '--', label='2PL IRT')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.legend(bbox_to_anchor=(1., 1.))\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "plt.xlabel('Learning update variance')\n",
    "plt.ylabel('Area under ROC Curve')\n",
    "plt.title('Validation Performance')\n",
    "\n",
    "plt.errorbar(\n",
    "    learning_update_variances,\n",
    "    [results.validation_auc_mean('d=2, with bias, var=%f' % v) for v in learning_update_variances],\n",
    "    yerr=[1.96 * results.validation_auc_stderr('d=2, with bias, var=%f' % v) for v in learning_update_variances],\n",
    "    label='d=2, with prereqs and bias')\n",
    "\n",
    "plt.plot(\n",
    "    learning_update_variances,\n",
    "    [results.validation_auc_mean('d=2, without lessons, with bias') for v in learning_update_variances],\n",
    "    label='d=2, without lessons, with bias')\n",
    "\n",
    "plt.plot(learning_update_variances,\n",
    "         [results.validation_auc_mean('0PL IRT (students)')] * len(learning_update_variances),\n",
    "         '--', label='0PL IRT (students)')\n",
    "plt.plot(learning_update_variances,\n",
    "         [results.validation_auc_mean('0PL IRT (assessments)')] * len(learning_update_variances),\n",
    "         '--', label='0PL IRT (assessments)')\n",
    "plt.plot(learning_update_variances, [results.validation_auc_mean('1PL IRT')] * len(learning_update_variances),\n",
    "         '--', label='1PL IRT')\n",
    "plt.plot(learning_update_variances, [results.validation_auc_mean('2PL IRT')] * len(learning_update_variances),\n",
    "         '--', label='2PL IRT')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.legend(bbox_to_anchor=(1., 1.))\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel('Dimension')\n",
    "ax.set_ylabel('Area under ROC Curve')\n",
    "ax.set_title('Validation Performance')\n",
    "\n",
    "for r in regularization_constants:\n",
    "    ax.plot(\n",
    "        dimensions,\n",
    "        [results.validation_auc_mean('%dD MIRT, with regularization_constant=%f' % (d, r)) for d in dimensions],\n",
    "        '-s',\n",
    "        label=('MIRT, lambda=%f' % r))\n",
    "\n",
    "ax.plot(dimensions, [results.validation_auc_mean('0PL IRT (students)')] * len(dimensions),\n",
    "        '--', label='0PL IRT (students)')\n",
    "ax.plot(dimensions, [results.validation_auc_mean('0PL IRT (assessments)')] * len(dimensions),\n",
    "        '--', label='0PL IRT (assessments)')\n",
    "ax.plot(dimensions, [results.validation_auc_mean('1PL IRT')] * len(dimensions),\n",
    "        '--', label='1PL IRT')\n",
    "ax.plot(dimensions, [results.validation_auc_mean('2PL IRT')] * len(dimensions),\n",
    "        '--', label='2PL IRT')\n",
    "\n",
    "ax.legend(loc='upper right')\n",
    "ax.legend(bbox_to_anchor=(1.5, 1.))\n",
    "ax.set_xscale('log')\n",
    "ax.set_xticks(dimensions)\n",
    "ax.set_xticklabels([str(x) for x in dimensions])\n",
    "ax.get_xaxis().get_major_formatter().labelOnlyBase = False\n",
    "ax.set_xlim([min(dimensions), max(dimensions)])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}